#   **01 网络编程基本概念** 

## **1.OSI与TCP/IP体系模型**

![图片](https://mmbiz.qpic.cn/mmbiz_png/j0ROiac4adEskl4nt6HgOGAXSGxvA3CQesjtmUhbW3yfguOj3dR9p5IBROshwqtGWz2kk7K8ibZf6hLL5xCb8YEA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/j0ROiac4adEskl4nt6HgOGAXSGxvA3CQeSmGBNL8e28no6FicLKZVeica70DcLaib4SiaWVmf7Rmu6d8EymMjsKCukA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## **2.IP和端口**

解决了文章最开始提到的定位的问题。

IP在互联网中能唯一标识一台计算机，是每一台计算机的唯一标识（身份证）；网络编程是和远程计算机的通信，所以必须先能定位到远程计算机；IP帮助解决此问题；一台计算机中可能有很多进程，具体和哪一个进程进行通信，这就得靠端口来识别；

**IP和端口能唯一定位到需要通信的进程。****这里的IP表示地址，区别于IP协议。在OSI体系还是TCP/IP体系中，IP协议位于网际层，来封装IP地址到报文中。**

## **3.TCP和UDP协议**

**TCP**是**Tranfer Control Protocol**的简称，是一种面向连接的保证可靠传输的协议。通过TCP协议传输，得到的是一个顺序的无差错的数据流。发送方和接收方的成对的两个socket之间必须建立连接，以便在TCP协议的基础上进行通信，当一个socket（通常都是server socket）等待建立连接时，另一个socket可以要求进行连接，一旦这两个socket连接起来，它们就可以进行双向数据传输，双方都可以进行发送或接收操作。

**UDP**是**User Datagram Protocol**的简称，是一种无连接的协议，每个数据报都是一个独立的信息，包括完整的源地址或目的地址，它在网络上以任何可能的路径传往目的地，因此能否到达目的地，到达目的地的时间以及内容的正确性都是不能被保证的。

**比较：**

UDP：

1. 每个数据报中都给出了完整的地址信息，因此无需要建立发送方和接收方的连接。
2. UDP传输数据时是有大小限制的，每个被传输的数据报必须限定在64KB之内。
3. UDP是一个不可靠的协议，发送方所发送的数据报并不一定以相同的次序到达接收方。

TCP：

1. 面向连接的协议，在socket之间进行数据传输之前必然要建立连接，所以在TCP中需要连接时间。
2. TCP传输数据大小限制，一旦连接建立起来，双方的socket就可以按统一的格式传输大的数据。
3. TCP是一个可靠的协议，它确保接收方完全正确地获取发送方所发送的全部数据。

**数据桢：**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/j0ROiac4adEskl4nt6HgOGAXSGxvA3CQeZU9Aia4vMRbdAA2Us6t9ticktXTfibTDBRzseED7CLpXEobicAMGkIs7zw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**应用：**

**TCP**在网络通信上有极强的生命力，例如远程连接（Telnet）和文件传输（FTP）都需要不定长度的数据被可靠地传输。但是可靠的传输是要付出代价的，对数据内容正确性的检验必然占用计算机的处理时间和网络的带宽，因此TCP传输的效率不如UDP高。

**UDP**操作简单，而且仅需要较少的监护，因此通常用于局域网高可靠性的分散系统中client/server应用程序。例如视频会议系统，并不要求音频视频数据绝对的正确，只要保证连贯性就可以了，这种情况下显然使用UDP会更合理一些。

## **4.Socket**

Socket是网络驱动层提供给应用程序编程接口和一种机制。我们可以把 Socket 比喻成是一个港口码头。应用程序只要把货物放到港口码头上，就算完成了货物的运送。对于接收方应用程序也要创建一个港口码头，只需要等待货物到达码头后将货物取走。

Socket 是在应用程序中创建的，它是通过一种绑定机制与驱动程序建立关系，告诉自己所对应的 IP 和 Port。在网络上传输的每一个数据帧，必须包含发送者的 IP 地址和端口号。创建完 Socket 以后，应用程序写入到 Socket 的数据，由 Socket 交给驱动程序向网络上发送数据，计算机从网络上收到与某个 Socket 绑定的 IP 和 Port 相关的数据后，由驱动程序再交给 Socket ，应用程序就可以从这个 Socket 中读取接收到的数据。网络应用程序就是这样通过 Socket 发送和接收的。

**Socket数据发送过程：**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/j0ROiac4adEskl4nt6HgOGAXSGxvA3CQeSqmiciaQtu4z57OAyCwXdEOWENDLEP1M3WiaBjKGIwZMIZ5RTuibKb5icCA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**Socket数据接收过程：**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/j0ROiac4adEskl4nt6HgOGAXSGxvA3CQeZCJfcO1LFbdQMKZ7THc1w0jS5xx9rVeicuBGqzGibqX2ic7Y6lbkOibsEQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

## **5.常用应用层协议**

应用层协议是为了解决某一类应用问题，而问题的解决又往往是通过位于不同主机中的多个应用进程之间的通信和协同工作来完成的。应用层的具体内容就是规定应用进程在通信时所遵循的协议。



#   **02 Java网络编程常用类 

**

## **1.InteAddress类**

Java中的InetAddress是一个代表IP地址的封装。IP地址可以由字节数组和字符串来分别表示，InetAddress将IP地址以对象的形式进行封装，可以更方便的操作和获取其属性。InetAddress没有构造方法，可以通过两个静态方法获得它的对象。

```
//根据主机名来获取对应的InetAddress实例
    InetAddress ip = InetAddress.getByName("www.baidu.com");
   //判断是否可达
   System.out.println("baidu是否可达：" + ip.isReachable(2000));
   //获取该InetAddress实例的IP字符串
   System.out.println(ip.getHostAddress());
   //根据原始IP地址(字节数组形式)来获取对应的InetAddress实例
       InetAddress local = InetAddress.getByAddress(new byte[]{127,0,0,1});
   System.out.println("本机是否可达：" + local.isReachable(5000));
   //获取该InetAddress实例对应的全限定域名
   System.out.println(local.getCanonicalHostName());
```

## **2.URL和URLConnection类**

网络中的URL（Uniform Resource Locator）是统一资源定位符的简称。它表示Internet上某一资源的地址。通过URL我们可以访问Internet上的各种网络资源，比如最常见的WWW，FTP站点。

URL可以被认为是指向互联网资源的“指针”，通过URL可以获得互联网资源相关信息，包括获得URL的InputStream对象获取资源的信息，以及一个到URL所引用远程对象的连接URLConnection。URLConnection对象可以向所代表的URL发送请求和读取URL的资源。通常，创建一个和URL的连接，需要如下几个步骤：

1. 创建URL对象，并通过调用openConnection方法获得URLConnection对象；
2. 设置URLConnection参数和普通请求属性；
3. 向远程资源发送请求；
4. 远程资源变为可用，程序可以访问远程资源的头字段和通过输入流来读取远程资源返回的信息。

这里需要重点讨论一下第三步：如果只是发送GET方式请求，使用connect方法建立和远程资源的连接即可；如果是需要发送POST方式的请求，则需要获取URLConnection对象所对应的输出流来发送请求。

这里需要注意的是，由于GET方法的参数传递方式是将参数显式追加在地址后面，那么在构造URL对象时的参数就应当是包含了参数的完整URL地址，而在获得了URLConnection对象之后，就直接调用connect方法即可发送请求。而POST方法传递参数时仅仅需要页面URL，而参数通过需要通过输出流来传递。另外还需要设置头字段。以下是两种方式的代码：

```
//1. 向指定URL发送GET方法的请求
String urlName = url + "?" + param;
URL realUrl = new URL(urlName);
//打开和URL之间的连接
URLConnection conn = realUrl.openConnection();
//设置通用的请求属性
conn.setRequestProperty("accept", "*/*");
conn.setRequestProperty("connection", "Keep-Alive");
conn.setRequestProperty("user-agent","Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)");
//建立实际的连接
conn.connect();    
//2. 向指定URL发送POST方法的请求
URL realUrl = new URL(url);
//打开和URL之间的连接
URLConnection conn = realUrl.openConnection(); 
//设置通用的请求属性
conn.setRequestProperty("accept", "*/*");
conn.setRequestProperty("connection", "Keep-Alive");
conn.setRequestProperty("user-agent", "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)"); 
//发送POST请求必须设置如下两行
conn.setDoOutput(true);
conn.setDoInput(true);
//获取URLConnection对象对应的输出流
out = new PrintWriter(conn.getOutputStream());
//发送请求参数
out.print(param);
```

## **3.URLDecoder和URLEncoder**

这两个类可以别用于将application/x-www-form-urlencoded MIME类型的字符串转换为普通字符串，将普通字符串转换为这类特殊型的字符串。使用URLDecoder类的静态方法decode()用于解码，URLEncoder类的静态方法encode()用于编码。具体使用方法如下：

```
//将application/x-www-form-urlencoded字符串转换成普通字符串  
String keyWord = URLDecoder.decode("%E6%9D%8E%E5%88%9A+j2ee", "UTF-8");  
System.out.println(keyWord);  
//将普通字符串转换成  application/x-www-form-urlencoded字符串  
String urlStr = URLEncoder.encode( "ROR敏捷开发最佳指南" , "GBK");  
System.out.println(urlStr);
```

## **4.Socket和ServerSocket类**

网络上的两个程序通过一个双向的通讯连接实现数据的交换，这个双向链路的一端称为一个Socket。Socket通常用来实现客户方和服务方的连接。Socket是TCP/IP协议的一个十分流行的编程界面，一个Socket由一个IP地址和一个端口号唯一确定。但是，Socket所支持的协议种类也不光TCP/IP一种，因此两者之间是没有必然联系的。

在Java环境下，Socket编程主要是指基于TCP/IP协议的网络编程。Server端Listen(监听)某个端口是否有连接请求，Client端向Server端发出Connect(连接)请求，Server端向Client端发回Accept（接受）消息。一个连接就建立起来了。Server端和Client端都可以通过Send，Write等方法与对方通信。

**TCP Socket的通信过程如下图：**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/j0ROiac4adEskl4nt6HgOGAXSGxvA3CQeVwjRDT1m9NxicKEhIiaXF0Z62w5Eeiaru0WHH1olDYaZzHRyzDCp88FBg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

## **5.DatagramSocket类**

UDP协议是一种不可靠的网络协议，它在通讯实例的两端个建立一个Socket，但这两个Socket之间并没有虚拟链路，这两个Socket只是发送和接受数据报的对象。包**java.net**中提供了两个类**DatagramSocket**和**DatagramPacket**用来支持数据报通信，DatagramSocket用于在程序之间建立传送数据报的通信连接， DatagramPacket则用来表示一个数据报。 **DatagramSocket的构造方法：**

```
DatagramSocket()；
DatagramSocket(int prot);
DatagramSocket(int port, InetAddress laddr);
```

其中，port指明socket所使用的端口号，如果未指明端口号，则把socket连接到本地主机上一个可用的端口。laddr指明一个可用的本地地址。给出端口号时要保证不发生端口冲突，否则会生成SocketException类例外。注意：上述的两个构造方法都声明抛弃非运行时例外SocketException，程序中必须进行处理，或者捕获、或者声明抛弃。用数据报方式编写client/server程序时，无论在客户方还是服务方，首先都要建立一个DatagramSocket对象，用来接收或发送数据报，然后使用DatagramPacket类对象作为传输数据的载体。







# 手把手教你写 Socket 长连接

原创 任玉刚 [玉刚说](javascript:void(0);) *2018-06-29 09:00*

> 本文由`玉刚说写作平台`[1]提供写作赞助
> 原作者：`水晶虾饺`[2]
> 版权声明：本文版权归微信公众号 `玉刚说` 所有，未经许可，不得以任何形式转载

本篇我们先简单了解一下 TCP/IP，然后通过实现一个 echo 服务器来学习 Java 的 Socket API。最后我们聊聊偏高级一点点的 socket 长连接和协议设计。

## TCP/IP 协议简介

#### IP

首先我们看 IP（Internet Protocol）协议。IP 协议提供了**主机和主机**间的通信。

为了完成不同主机的通信，我们需要某种方式来唯一标识一台主机，这个标识，就是著名的**IP地址**。通过IP地址，IP 协议就能够帮我们把一个数据包发送给对方。

#### TCP

前面我们说过，IP 协议提供了主机和主机间的通信。TCP 协议在 IP 协议提供的主机间通信功能的基础上，完成这两个主机上**进程对进程**的通信。

有了 IP，不同主机就能够交换数据。但是，计算机收到数据后，并不知道这个数据属于哪个进程（简单讲，进程就是一个正在运行的应用程序）。TCP 的作用就在于，让我们能够知道这个数据属于哪个进程，从而完成进程间的通信。

为了标识数据属于哪个进程，我们给需要进行 TCP 通信的进程分配一个唯一的数字来标识它。这个数字，就是我们常说的**端口号**。

TCP 的全称是 Transmission Control Protocol，大家对它说得最多的，大概就是**面向连接**的特性了。之所以说它是有连接的，是说在进行通信前，通信双方需要先经过一个*三次握手*的过程。三次握手完成后，连接便建立了。这时候我们才可以开始发送/接收数据。（与之相对的是 UDP，不需要经过握手，就可以直接发送数据）。

下面我们简单了解一下三次握手的过程。

![图片](https://mmbiz.qpic.cn/mmbiz_png/zKFJDM5V3WyBBhtrBTSq6HiacQjdDkhnn18dMxN6FlgzJUPG38vzgcHmWHIPBOE2LYSVw9En5beP8W5HQ68BdzQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)tcp-three-way-handshake

1. 首先，客户向服务端发送一个 `SYN`，假设此时 sequence number 为 `x`。这个 `x` 是由操作系统根据一定的规则生成的，不妨认为它是一个随机数。
2. 服务端收到 `SYN` 后，会向客户端再发送一个 `SYN`，此时服务器的 `seq number = y`。与此同时，会 `ACK x+1`，告诉客户端“已经收到了 `SYN`，可以发送数据了”。
3. 客户端收到服务器的 `SYN` 后，回复一个 `ACK y+1`，这个 `ACK` 则是告诉服务器，`SYN` 已经收到，服务器可以发送数据了。

经过这 3 步，TCP 连接就建立了。这里需要注意的有三点：

1. 连接是由客户端主动发起的
2. 在第 3 步客户端向服务器回复 `ACK` 的时候，TCP 协议是允许我们携带数据的。之所以做不到，是 API 的限制导致的。
3. TCP 协议还允许 “四次握手” 的发生，同样的，由于 API 的限制，这个极端的情况并不会发生。

TCP/IP 相关的理论知识我们就先了解到这里。关于 TCP，还有诸如可靠性、流量控制、拥塞控制等非常有趣的特性，**强烈推荐**读者看一看 Richard 的名著《TCP/IP 详解 - 卷1》（注意，是**第1版**，不是第2版）。

下面我们看一些偏实战的东西。

## Socket 基本用法

Socket 是 TCP 层的封装，通过 socket，我们就能进行 TCP 通信。

在 Java 的 SDK 中，socket 的共有两个接口：用于监听客户连接的 `ServerSocket` 和用于通信的 `Socket`。使用 socket 的步骤如下：

1. 创建 `ServerSocket` 并监听客户连接
2. 使用 `Socket` 连接服务端
3. 通过 `Socket` 获取输入输出流进行通信

下面，我们通过实现一个简单的 echo 服务来学习 socket 的使用。所谓的 echo 服务，就是客户端向服务端写入任意数据，服务器都将数据原封不动地写回给客户端。

**1. 创建 ServerSocket 并监听客户连接**

```
public class EchoServer {

    private final ServerSocket mServerSocket;

    public EchoServer(int port) throws IOException {
        // 1. 创建一个 ServerSocket 并监听端口 port
        mServerSocket = new ServerSocket(port);
    }

    public void run() throws IOException {
        // 2. 开始接受客户连接
        Socket client = mServerSocket.accept();
        handleClient(client);
    }

    private void handleClient(Socket socket) {
        // 3. 使用 socket 进行通信 ...
    }


    public static void main(String[] argv) {
        try {
            EchoServer server = new EchoServer(9877);
            server.run();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

**2. 使用 Socket 连接服务端**

```
public class EchoClient {

    private final Socket mSocket;

    public EchoClient(String host, int port) throws IOException {
        // 创建 socket 并连接服务器
        mSocket = new Socket(host, port);
    }

    public void run() {
        // 和服务端进行通信
    }


    public static void main(String[] argv) {
        try {
            // 由于服务端运行在同一主机，这里我们使用 localhost
            EchoClient client = new EchoClient("localhost", 9877);
            client.run();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

**3. 通过 socket 获取输入/输出流进行通信**

首先，我们来实现服务端：

```
public class EchoServer {
    // ...

    private void handleClient(Socket socket) throws IOException {
        InputStream in = socket.getInputStream();
        OutputStream out = socket.getOutputStream();
        byte[] buffer = new byte[1024];
        int n;
        while ((n = in.read(buffer)) > 0) {
            out.write(buffer, 0, n);
        }
    }
}
```

可以看到，服务端的实现其实很简单，我们不停地读取输入数据，然后写回给客户端。

下面我们看看客户端。

```
public class EchoClient {
    // ...

    public void run() throws IOException {
        Thread readerThread = new Thread(this::readResponse);
        readerThread.start();

        OutputStream out = mSocket.getOutputStream();
        byte[] buffer = new byte[1024];
        int n;
        while ((n = System.in.read(buffer)) > 0) {
            out.write(buffer, 0, n);
        }
    }

    private void readResponse() {
        try {
            InputStream in = mSocket.getInputStream();
            byte[] buffer = new byte[1024];
            int n;
            while ((n = in.read(buffer)) > 0) {
                System.out.write(buffer, 0, n);
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

客户端会稍微复杂一点点，在读取用户输入的同时，我们又想读取服务器的响应。所以，这里创建了一个线程来读服务器的响应。

不熟悉 lambda 的读者，可以把
`Thread readerThread = new  Thread(this::readResponse)`
换成下面这个代码：

```
Thread readerThread = new Thread(new Runnable() {
    @Override
    public void run() {
        readResponse();
    }
});
```

打开两个 terminal 分别执行如下命令：

```
$ javac EchoServer.java
$ java EchoServer
$ javac EchoClient.java
$ java EchoClient
hello Server
hello Server
foo
foo
```

在客户端，我们会看到，输入的所有字符都打印了出来。

最后需要注意的有几点：

1. 在上面的代码中，我们所有的异常都没有处理。实际应用中，在发生异常时，需要关闭 socket，并根据实际业务做一些错误处理工作
2. 在客户端，我们没有停止 `readThread`。实际应用中，我们可以通过关闭 socket 来让线程从阻塞读中返回。推荐读者阅读《Java并发编程实战》
3. 我们的服务端只处理了一个客户连接。如果需要同时处理多个客户端，可以创建线程来处理请求。这个作为练习留给读者来完全。

## Socket、ServerSocket 傻傻分不清楚

在进入这一节的主题前，读者不妨先考虑一个问题：在上一节的实例中，我们运行 echo 服务后，在客户端连接成功时，一个有多少个 socket 存在？

答案是 3 个 socket。客户端一个，服务端有两个。跟这个问题的答案直接关联的是本节的主题——`Socket` 和 `ServerSocket` 的区别是什么。

眼尖的读者，可能会注意到在上一节我是这样描述他们的：

> 在 Java 的 SDK 中，socket 的共有两个接口：用于监听客户连接的 `ServerSocket` 和用于通信的 `Socket`。

注意，我只说 `ServerSocket` 是用于监听客户连接，而没有说它也可以用来通信。下面我们来详细了解一下他们的区别。

> 注：以下描述使用的是 UNIX/Linux 系统的 API

首先，我们创建 `ServerSocket` 后，内核会创建一个 socket。这个 socket 既可以拿来监听客户连接，也可以连接远端的服务。由于 `ServerSocket` 是用来监听客户连接的，紧接着它就会对内核创建的这个 socket 调用 `listen` 函数。这样一来，这个 socket 就成了所谓的 listening socket，它开始监听客户的连接。

接下来，我们的客户端创建一个 `Socket`，同样的，内核也创建一个 socket 实例。内核创建的这个 socket 跟 `ServerSocket` 一开始创建的那个没有什么区别。不同的是，接下来 `Socket` 会对它执行 `connect`，发起对服务端的连接。前面我们说过，socket API 其实是 TCP 层的封装，所以 `connect` 后，内核会发送一个 `SYN` 给服务端。

现在，我们切换角色到服务端。**服务端的主机在收到这个 `SYN` 后，会创建一个新的 socket**，这个新创建的 socket 跟客户端继续执行三次握手过程。

三次握手完成后，我们执行的 `serverSocket.accept()` 会返回一个 `Socket` 实例，这个 socket 就是上一步内核自动帮我们创建的。

所以说，在一个客户端连接的情况下，其实有 3 个 socket。

关于内核自动创建的这个 socket，还有一个很有意思的地方。它的端口号跟 `ServerSocket` 是一毛一样的。咦！！不是说，一个端口只能绑定一个 socket 吗？其实这个说法并不够准确。

前面我说的TCP 通过端口号来区分数据属于哪个进程的说法，在 socket 的实现里需要改一改。Socket 并不仅仅使用端口号来区别不同的 socket 实例，而是使用 `<peer addr:peer port, local addr:local port>` 这个四元组。

在上面的例子中，我们的 `ServerSocket` 长这样：`<*:*, *:9877>`。意思是，可以接受任何的客户端，和本地任何 IP。

`accept` 返回的 `Socket` 则是这样：
`<127.0.0.1:xxxx, 127.0.0.1:9877>`，其中`xxxx` 是客户端的端口号。

如果数据是发送给一个已连接的 socket，内核会找到一个完全匹配的实例，所以数据准确发送给了对端。

如果是客户端要发起连接，这时候只有 `<*:*, *:9877>` 会匹配成功，所以 `SYN` 也准确发送给了监听套接字。

`Socket/ServerSocket` 的区别我们就讲到这里。如果读者觉得不过瘾，可以参考《TCP/IP 详解》卷1、卷2。

## Socket 长连接的实现

**背景知识**

Socket 长连接，指的是在客户和服务端之间保持一个 socket 连接长时间不断开。

比较熟悉 `Socket` 的读者，可能知道有这样一个 API：

```
socket.setKeepAlive(true);
```

嗯……keep alive，“保持活着”，这个应该就是让 TCP 不断开的意思。那么，我们要实现一个 socket 的长连接，只需要这一个调用即可。

遗憾的是，生活并不总是那么美好。对于 4.4BSD 的实现来说，Socket 的这个 keep alive 选项如果打开并且**两个小时**内没有通信，那么底层会发一个心跳，看看对方是不是还活着。

注意，两个小时才会发一次。也就是说，在没有实际数据通信的时候，我把网线拔了，你的应用程序要经过两个小时才会知道。

在说明如果实现长连接前，我们先来理一理我们面临的问题。假定现在有一对已经连接的 socket，在以下情况发生时候，socket 将不再可用：

1. 某一端关闭是 socket（这不是废话吗）。主动关闭的一方会发送 `FIN`，通知对方要关闭 TCP 连接。在这种情况下，另一端如果去读 socket，将会读到 `EoF`（End of File）。于是我们知道对方关闭了 socket。
2. 应用程序奔溃。此时 socket 会由内核关闭，结果跟情况1一样。
3. 系统奔溃。这时候系统是来不及发送 `FIN` 的，因为它已经跪了。此时对方无法得知这一情况。对方在尝试读取数据时，最后会返回 read time out。如果写数据，则是 host unreachable 之类的错误。
4. 电缆被挖断、网线被拔。跟情况3差不多，如果没有对 socket 进行读写，两边都不知道发生了事故。跟情况3不同的是，如果我们把网线接回去，socket 依旧可以正常使用。

在上面的几种情形中，有一个共同点就是，只要去读、写 socket，只要 socket 连接不正常，我们就能够知道。基于这一点，要实现一个 socket 长连接，我们需要做的就是不断地给对方写数据，然后读取对方的数据，也就是所谓的**心跳**。只要心还在跳，socket 就是活的。写数据的间隔，需要根据实际的应用需求来决定。

心跳包不是实际的业务数据，根据通信协议的不同，需要做不同的处理。

比方说，我们使用 JSON 进行通信，那么，我们可以加一个 `type` 字段，表面这个 JSON 是心跳还是业务数据。

```
{
    "type": 0,  // 0 表示心跳

    // ...
}
```

使用二进制协议的情况类似。要求就是，我们能够区别一个数据包是心跳还是真实数据。这样，我们便实现了一个 socket 长连接。

**实现示例**

这一小节我们一起来实现一个带长连接的 Android echo 客户端。

首先了接口部分：

```
public final class LongLiveSocket {

    /**
     * 错误回调
     */
    public interface ErrorCallback {
        /**
         * 如果需要重连，返回 true
         */
        boolean onError();
    }

    /**
     * 读数据回调
     */
    public interface DataCallback {
        void onData(byte[] data, int offset, int len);
    }

    /**
     * 写数据回调
     */
    public interface WritingCallback {
        void onSuccess();
        void onFail(byte[] data, int offset, int len);
    }


    public LongLiveSocket(String host, int port,
                          DataCallback dataCallback, ErrorCallback errorCallback) {
    }

    public void write(byte[] data, WritingCallback callback) {
    }

    public void write(byte[] data, int offset, int len, WritingCallback callback) {
    }

    public void close() {
    }
}
```

我们这个支持长连接的类就叫 `LongLiveSocket` 好了。如果在 socket 断开后需要重连，只需要在对应的接口里面返回 true 即可（在真实场景里，我们还需要让客户设置重连的等待时间，还有读写、连接的 timeout等。为了简单，这里就直接不支持了。

另外需要注意的一点是，如果要做一个完整的库，需要同时提供阻塞式和回调式API。同样由于篇幅原因，这里直接省掉了。

首先我们看看 `write()` 方法：

```
public void write(byte[] data, int offset, int len, WritingCallback callback) {
    mWriterHandler.post(() -> {
        Socket socket = getSocket();
        if (socket == null) {
            // initSocket 失败而客户说不需要重连，但客户又叫我们给他发送数据
            throw new IllegalStateException("Socket not initialized");
        }
        try {
            OutputStream outputStream = socket.getOutputStream();
            DataOutputStream out = new DataOutputStream(outputStream);
            out.writeInt(len);
            out.write(data, offset, len);
            callback.onSuccess();
        } catch (IOException e) {
            Log.e(TAG, "write: ", e);
            // 关闭 socket，避免资源泄露
            closeSocket();
            // 这里我们把发生失败的数据返回给客户端，这样客户可以更方便地重新发送数据
            callback.onFail(data, offset, len);
            if (!closed() && mErrorCallback.onError()) {
                // 重连
                initSocket();
            }
        }
    });
}
```

由于我们需要定时写心跳，这里使用一个 `HandlerThread` 来处理写请求。通信使用的协议，只是简单地在用户数据前加一个 len 字段，用于确定消息的长度。

下面我们看心跳的发送：

```
private final Runnable mHeartBeatTask = new Runnable() {
    private byte[] mHeartBeat = new byte[0];

    @Override
    public void run() {
        // 我们使用长度为 0 的数据作为 heart beat
        write(mHeartBeat, new WritingCallback() {
            @Override
            public void onSuccess() {
                // 每隔 HEART_BEAT_INTERVAL_MILLIS 发送一次
                mWriterHandler.postDelayed(mHeartBeatTask, HEART_BEAT_INTERVAL_MILLIS);
                mUIHandler.postDelayed(mHeartBeatTimeoutTask, HEART_BEAT_TIMEOUT_MILLIS);
            }

            @Override
            public void onFail(byte[] data, int offset, int len) {
                // nop
                // write() 方法会处理失败
            }
        });
    }
};

private final Runnable mHeartBeatTimeoutTask = () -> {
    Log.e(TAG, "mHeartBeatTimeoutTask#run: heart beat timeout");
    closeSocket();
};
```

发送心跳使用我们上面实现的 `write()` 方法。在发送成功后，post delay 一个 timeout task，如果到期后还没收到服务器的响应，我们将认为 socket 出现异常，这里直接关闭 socket。最后是对心跳的处理：

```
int nbyte = in.readInt();
if (nbyte == 0) {
    Log.i(TAG, "readResponse: heart beat received");
    mUIHandler.removeCallbacks(mHeartBeatTimeoutTask);
}
```

由于用户数据的长度总是会大于 1，这里我们就使用 `len == 0` 的数据作为心跳。收到心跳后，移除 `mHeartBeatTimeoutTask`。

剩余代码跟我们的主题没有太大关系，读者在这里[3]可以找到完整的代码或者自己完成这个例子。

最后需要说明的是，如果想节省资源，在有客户发送数据的时候可以省略 heart beat。

我们对读出错时候的处理，可能也存在一些争议。读出错后，我们只是关闭了 socket。socket 需要等到下一次写动作发生时，才会重新连接。实际应用中，如果这是一个问题，在读出错后可以直接开始重连。这种情况下，还需要一些额外的同步，避免重复创建 socket。heart beat timeout 的情况类似。

## 跟 TCP/IP 学协议设计

如果仅仅是为了使用是 socket，我们大可以不去理会协议的细节。之所以推荐大家去看一看《TCP/IP 详解》，是因为它们有太多值得学习的地方。很多我们工作中遇到的问题，都可以在这里找到答案。

以下每一个小节的标题都是一个小问题，建议读者独立思考一下，再继续往下看。如果你发现你的答案比我的更好，请一定发送邮件到 ljtong64 AT gmail DOT com 告诉我。

#### 协议版本如何升级？

有这么一句流行的话：这个世界唯一不变的，就是变化。当我们对协议版本进行升级的时候，正确识别不同版本的协议对软件的兼容非常重要。那么，我们如何设计协议，才能够为将来的版本升级做准备呢？

答案可以在 IP 协议找到。

IP 协议的第一个字段叫 version，目前使用的是 4 或 6，分别表示 IPv4 和 IPv6。由于这个字段在协议的开头，接收端收到数据后，只要根据第一个字段的值就能够判断这个数据包是 IPv4 还是 IPv6。

再强调一下，这个字段在两个版本的IP协议都位于第一个字段，为了做兼容处理，对应的这个字段必须位于同一位置。文本协议（如，JSON、HTML）的情况类似。

#### 如何发送不定长数据的数据包

举个例子，我们用微信发送一条消息。这条消息的长度是不确定的，并且每条消息都有它的边界。我们如何来处理这个边界呢？

还是一样，看看 IP。IP 的头部有个 header length 和 data length 两个字段。通过添加一个 len 域，我们就能够把数据根据应用逻辑分开。

跟这个相对的，还有另一个方案，那就是在数据的末尾放置终止符。比方说，想 C 语言的字符串那样，我们在每个数据的末尾放一个 `\0` 作为终止符，用以标识一条消息的尾部。这个方法带来的问题是，用户的数据也可能存在 `\0`。此时，我们就需要对用户的数据进行**转义**。比方说，把用户数据的所有 `\0` 都变成 `\0\0`。读消息的过程总，如果遇到 `\0\0`，那它就代表 `\0`，如果只有一个 `\0`，那就是消息尾部。

使用 len 字段的好处是，我们不需要对数据进行转义。读取数据的时候，只要根据 len 字段，一次性把数据都读进来就好，效率会更高一些。

终止符的方案虽然要求我们对数据进行扫描，但是如果我们可能从任意地方开始读取数据，就需要这个终止符来确定哪里才是消息的开头了。

当然，这两个方法不是互斥的，可以一起使用。

#### 上传多个文件，只有所有文件都上传成功时才算成功

现在我们有一个需求，需要一次上传多个文件到服务器，只有在所有文件都上传成功的情况下，才算成功。我们该如何来实现呢？

IP 在数据报过大的时候，会把一个数据报拆分成多个，并设置一个 MF （more fragments）位，表示这个包只是被拆分后的数据的一部分。

好，我们也学一学 IP。这里，我们可以给每个文件从 0 开始编号。上传文件的同时，也携带这个编号，并额外附带一个 MF 标志。除了编号最大的文件，所有文件的 MF 标志都置位。因为 MF 没有置位的是最后一个文件，服务器就可以根据这个得出总共有多少个文件。

另一种不使用 MF 标志的方法是，我们在上传文件前，就告诉服务器总共有多少个文件。

如果读者对数据库比较熟悉，学数据库用事务来处理，也是可以的。这里就不展开讨论了。

#### 如何保证数据的有序性

这里讲一个我曾经遇到过的面试题。现在有一个任务队列，多个工作线程从中取出任务并执行，执行结果放到一个结果队列中。先要求，放入结果队列的时候，顺序顺序需要跟从工作队列取出时的一样（也就是说，先取出的任务，执行结果需要先放入结果队列）。

我们看看 TCP/IP 是怎么处理的。IP 在发送数据的时候，不同数据报到达对端的时间是不确定的，后面发送的数据有可能较先到达。TCP 为了解决这个问题，给所发送数据的每个字节都赋了一个序列号，通过这个序列号，TCP 就能够把数据按原顺序重新组装。

一样，我们也给每个任务赋一个值，根据进入工作队列的顺序依次递增。工作线程完成任务后，在将结果放入结果队列前，先检查要放入对象的写一个序列号是不是跟自己的任务相同，如果不同，这个结果就不能放进去。此时，最简单的做法是等待，知道下一个可以放入队列的结果是自己所执行的那一个。但是，这个线程就没办法继续处理任务了。

更好的方法是，我们维护多一个结果队列的缓冲，这个缓冲里面的数据按序列号从小到大排序。工作线程要将结果放入，有两种可能：

1. 刚刚完成的任务刚好是下一个，将这个结果放入队列。然后从缓冲的头部开始，将所有可以放入结果队列的数据都放进去。
2. 所完成的任务不能放入结果队列，这个时候就插入结果队列。然后，跟上一种情况一样，需要检查缓冲。

如果测试表明，这个结果缓冲的数据不多，那么使用普通的链表就可以。如果数据比较多，可以使用一个最小堆。

#### 如何保证对方收到了消息

我们说，TCP 提供了可靠的传输。这样不就能够保证对方收到消息了吗？

很遗憾，其实不能。在我们往 socket 写入的数据，只要对端的内核收到后，就会返回 `ACK`，此时，socket 就认为数据已经写入成功。然而要注意的是，这里只是对方所运行的系统的内核成功收到了数据，并不表示应用程序已经成功处理了数据。

解决办法还是一样，我们学 `TCP`，添加一个应用层的 `APP ACK`。应用接收到消息并处理成功后，发送一个 `APP ACK` 给对方。

有了 `APP ACK`，我们需要处理的另一个问题是，如果对方真的没有收到，需要怎么做？

TCP 发送数据的时候，消息一样可能丢失。TCP 发送数据后，如果长时间没有收到对方的 `ACK`，就假设数据已经丢失，并重新发送。

我们也一样，如果长时间没有收到 `APP ACK`，就假设数据丢失，重新发送一个。

附：
[1] http://renyugang.io/post/75
[2] https://jekton.github.io
[3] https://github.com/Jekton/Echo

# 套接字IO高并发？(一)

原创 坤哥 [码海](javascript:void(0);) *2022-08-03 18:00* *发表于浙江*

你好，我是坤哥

准备写一个针对高并发的系列，今天我们先聊一下高并发下的网络 IO 模型设计

高并发即我们所说的 C10K（一个server 服务 1w 个 client）,C10M，写出高并发的程序相信是每个后端程序员的追求，高并发架构其实有一些很通用的架构设计，如无锁化，缓存等，今天我们主要研究下高并发下的网络 IO 模型设计，我们知道不管是 Nginx，还是 Redis，Kafka，RocketMQ 等中间件，都能轻松支持非常高的 QPS，其实它们背后的网络 IO 模型设计理念都是一致的，所以了解这一块对我们了解设计出高并发的网络 IO 框架具体重要意义，本文将会从以下几个方面来循序渐近地向大家介绍如何设计出一个高并发的网络 IO 框架

- 传统网络 IO 模型的缺陷
- 针对传统网络 IO 模型缺陷的改进
- 多线程/多进程
- 阻塞改为非阻塞
- IO 多路复用
- Reactor 的几种模型介绍

### 传统网络 IO 模型的缺陷

我们首先来看下传统网络 IO 模型有哪些缺陷，主要看它们的阻塞点有哪些。我们用一张图来看下客户端和服务端的基于 TCP 的通信流程

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGsmu15WsiaW6uTJYeEE1fFNy7mIU6ic4XDFOzWoXAPrSXRnho69NhrAAA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

服务端的伪代码如下

```
listenSocket = socket(); //调用socket系统调用创建一个主动套接字
bind(listenSocket);  //绑定地址和端口
listen(listenSocket); //将默认的主动套接字转换为服务器使用的被动套接字，也就是监听套接字
while (1) { //循环监听是否有客户端连接请求到来
   connSocket = accept(listenSocket); //接受客户端连接
   recv(connsocket); //从客户端读取数据，只能同时处理一个客户端
   send(connsocket); //给客户端返回数据，只能同时处理一个客户端
}
```

可以看到，主要的通信流程如下

1. server 创建监听 socket 后，执行 bind() 绑定 IP 和端口，然后调用 listen() 监听，代表 server 已经准备好接收请求了，listen 的主要作用其实是初始化半连接和全连接队列大小
2. server 准备好后，client 也创建 socket ，然后执行 connect 向 server 发起连接请求，**这一步会被阻塞**，需要等待三次握手完成，第一次握手完成，服务端会创建 socket（这个 socket 是连接 socket，注意不要和第一步的监听 socket 搞混了）,将其放入半连接队列中，第三次握手完成，系统会把 socket 从半连接队列摘下放入全连接队列中，然后 accept 会将其从全连接队列中摘下，之后此 socket 就可以与客户端 socket 正常通信了，默认情况下如果全连接队列里没有 socket，则 accept 会**阻塞等待**三次握手完成

经过三次握手后 client 和 server 就可以基于 socket 进行正常的进程通信了（即调用 write 发送写请求，调用 read 执行读请求），但需要注意的是 read，write 也很可能会被阻塞，需要满足一定的条件读写才会成功返回，在 LInux 中一切皆文件，socket 也不例外，每个打开的文件都有读写缓冲区，如下图所示

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGx7LOXZB1XrzwCjcoZtXfYETaERELItb5nwjHqlwY7VAD5fktOZRmWg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

对文件执行 read()，write() 的具体流程如下

1. 当执行 read() 时，会从内核读缓冲区中读取数据，如果缓冲区中没有数据，则会**阻塞等待**，等数据到达后，会通过 DMA 拷贝将数据拷贝到内核读缓冲区中，然后会唤醒用户线程将数据从内核读缓冲区拷贝到应用缓冲区中
2. 当执行 write() 时，会将数据从应用缓冲区拷贝到内核写缓冲区，然后再通过 DMA 拷贝将数据从写缓冲区发送到设备上传输出去，如果写缓冲区满，则 write 会**阻塞等待**写缓冲区可写

经过以上分析，我们可以看到传统的 socket 通信会阻塞在 connect，accept，read/write 这几个操作上，这样的话如果 server 是单进程/线程的话，只要 server 阻塞，就不能再接收其他 client 的处理了，由此可知**传统的 socket 无法支持 C10K**

### 针对传统网络 IO 模型缺陷的改进

接下来我们来看看针对传统 IO 模型缺陷的改进，主要有两种

1. 多进程/线程模型
2. IO 多路程复用

#### 多进程/线程模型

如果 server 是单进程，阻塞显然会导致 server 无法再处理其他 client 请求了，那我们试试把 server 改成多进程的？只要父进程 accept 了 socket ，就 fork 一个子进程，把这个 socket 交给子进程处理，这样就算子进程阻塞了，也不影响父进程继续监听和其他子进程处理连接

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGGB9v3cLoSGWq3Ov8aDL8KY3wnx3JkV4ZQvib00QbyYibfXO8c2GbOAVw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

程序伪代码如下

```
while(1) {
  connfd = accept(listenfd);  // 阻塞建立连接
  // fork 创建一个新进程
  if (fork() == 0) {
    // accept 后子进程开始工作
    doWork(connfd);
  }
}
void doWork(connfd) {
  int n = read(connfd, buf);  // 阻塞读数据
  doSomeThing(buf);  // 利用读到的数据做些什么
  close(connfd);     // 关闭连接，循环等待下一个连接
}
```

通过这种方式确实解决了单进程 server 阻塞无法处理其他 client 请求的问题，但众所周知 fork 创建子进程是非常耗时的，包括页表的复制，进程切换时页表的切换等都非常耗时，每来一个请求就创建一个进程显然是无法接受的

为了节省进程创建的开销，于是有人提出把多进程改成多线程，创建线程（使用 pthread_create）的开销确实小了很多，但同样的，线程与进程一样，都需要占用堆栈等资源，而且碰到阻塞，唤醒等都涉及到用户态，内核态的切换，这些都极大地消耗了性能

由此可知采用多进程/线程的方式并不可取

**画外音**: 在 Linux 下进程和线程都是用统一的 task_struct 表示，区别不大，所以下文描述不管是进程还是线程区别都不大

#### 阻塞改为非阻塞

既然多进程/多线程的方式并不可取，那能否将进程的阻塞操作（connect，accept，read/write）改为非阻塞呢，这样只要调用这些操作，如果相应的事件未准备好，就立马返回 EWOULDBLOCK 或 EAGAIN 错误，此时进程就不会被阻塞了，使用 fcntl 可以可以将 socket 设置为非阻塞，以 read 为例伪代码如下

```
connfd = accept(listenfd);
fcntl(connfd, F_SETFL, O_NONBLOCK);
// 此时 connfd 变为非阻塞，如果数据未就绪，read 会立即返回
int n = read(connfd, buffer) != SUCCESS; 
```

read 的非阻塞操作流程图如下

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGRxb9aGeibq1RPicWFPJBnUTodH8hUOBvOnrRgRJcow9hDS34UlNKJuMw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)非阻塞read

非阻塞read

这样的话调用 read 就不会阻塞等待而会马上返回了，也就实现了非阻塞的效果，不过需要注意的，我们这里说的非阻塞并非严格意义上的非阻塞，这里的非阻塞只是针对网卡数据拷贝到内核缓冲区这一段，如果数据就绪后，再执行 read 此时依然是阻塞的，此时用户进程会占用 CPU 去把数据从内核缓冲区拷贝到用户缓冲区中，可以看到这种模式是**同步非阻塞**的，这里我们简单解释下阻塞/非阻塞，同步/非同步的概念

- **阻塞/非阻塞**指的是在数据从网卡拷贝到内核缓冲区期间，**进程能不能动**，如果能动，就是非阻塞的，不能动就是阻塞的

- **同步/非同步**指的是数据就绪后**是否需要用户进程亲自调用 read 来搬运数据（将数据从内核空间拷贝到用户空间）** ，如果需要，则是同步，如果不需要则是非同步（即异步），异步 I/O 示意图如下：

  ![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGhYwBsZzv7APcztuE45Yv4cfWZIJZZjXicLHZxpl7AFv7MEWmktF3yqQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)异步 IO

  异步 IO

异步 IO 执行流程如下：进程发起 I/O 请求后，让内核在整个操作处理完后再通知进程，这整个操作包括网卡拷贝数据到内核缓冲区，将数据从内核缓冲区拷贝到用户缓冲区这两个阶段，内核在处理数据期间（从无数据到拷贝完成），应用进程是可以继续执行其他逻辑的，异步编程需要操作系统支持，目前只有 windows 完美支持，Linux 暂不支持。可以看出异步 I/O 才是真正意义上的非阻塞操作，因为数据从内核缓冲区拷贝到用户缓冲区这一步不需要用户进程来操作，而是由内核代劳了

我们以一个案例来总结下阻塞/非阻塞，同步/异步：当你去餐馆点餐时，如果在厨师做菜期间，你啥也不能干，那就是阻塞，如果在此期间你可以玩手机，喝喝茶，**能动**，那就是非阻塞，如果厨师做好了菜，你需要亲自去拿，那就是同步，如果厨师做好了，菜由服务员直接送到你的餐桌，那就是非同步（异步）

现在回过头来看将阻塞转成非阻塞是否满足了我们的需求呢？看起来进程确实可以动了，但进程需要不断地以轮询数据的形式调用 accept，read/write 这些操作来询问内核数据是否就绪了，这些都是系统调用，对性能的消耗很大，而且会持续占用 CPU，导致 CPU 负载很高，**远不如等数据就绪好了再通知进程去取更高效**。这就好比，厨师做菜期间，你不断地去问菜做好了没有，显然没有意义，更高效的方式无疑是等厨师菜做好了主动通知你去取

#### IO 多路复用

经过前面的分析我们可以得出两个结论

1. 使用多进程/多线程 IO 模型是不可行的，这一步可以优化为单线程
2. 应该等数据就绪好了之后再通知用户进程去读取数据，而不是做毫无意义的轮询，注意这里的数据就绪不光是指前文所述的 read 的数据已就绪，而是泛指 accept，read/write 这三个事件的数据都已就绪

于是 IO 多路复用模型诞生了，它是指用一个进程来监听 listen socket（监听 socket） 的连接建立事件，connect socket（已连接 socket） 的读写事件（读写），一旦数据就绪，内核就会唤醒用户进程去处理这些 socket 的相应的事件

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGHFicBibZnNIyZdcAXRz4ux3vhbqGM9HnwL16yp4mhnWfRI4ew56I260g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)IO多路复用

IO多路复用

这里简单介绍一下 fd（文件描述符），以便大家更好地了解之后 IO 多路复用中出现的 fd 集合等概念

#### 文件系统简介

我们知道在 Linux 中无论是文件，socket，还是管道，设备等，一切皆文件，Linux 抽象出了一个 VFS（virtual file system） 层，屏蔽了所有的具体的文件，VFS 提供了统一的接口给上层调用，这样应用层只与 VFS 打交道，极大地方便了用户的开发，仔细对比你会发现，这和 Java 中的面向接口编程很类似

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGNqKBCa4tkhich7vvAz54uL52eCAhnbDzl1ZcibRsu1ftPmtOmEZ3Kibew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

通过 open()，socket() 创建文件后，都有一个 fd（文件描述符） 与之对应，对于每一个进程，都有一个文件描述符列表（File Discriptor Table） 来记录其打开的文件，这个列表的每一项都指向其背后的具体文件，而**每一项对应的数组下标就是 fd**，对于用户而言，可以认为 fd 代表其背后指向的文件

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGTdicOcdodIvsf7iaficQcEQUdDkGoNwKhURPkZtVrZFkAC3wezD4ofFXQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

fd 的值从 0 开始，其中 0，1，2 是固定的，分别指向标准输入（指向键盘），标准输出/标准错误（指向显示器），之后每打开一个文件，fd 都会从 3 开始递增，但需要注意的是 fd 并不一定都是递增的，如果关闭了文件，之前的 fd 是可以被回收利用的

IO 多路复用其实也就是用一个进程来监听多个 fd 的数据事件，用户可以把自己感兴趣的 fd 及对应感兴趣的事件（accept，read/write）传给内核，然后内核就会检测 fd ，一旦某个 socket 有事件了，内核可以唤醒用户进程来处理

那么怎样才能知道某个 fd 是否有事件呢，一种很容易想到的做法是搞个轮询，每次调用一下 read(fd)，让内核告知是否数据已就绪，但是这样的话如果有 n 个感兴趣的 fd 就会有 n 次 read 系统调用，开销很大，显然不可接受

所以使用 IO 多路复用监听 fd 的事件可行，但必须解决以下三个涉及到性能瓶颈的点

1. 如何**高效**将用户感兴趣的 fd 和事件传给内核
2. 某个 socket 数据就绪后，内核如何**高效**通知用户进程进行处理
3. 用户进程如何高效处理事件

前面两步的处理目前有 select，poll，epoll 三种 IO 多路事件模型，我们一起来看看，看完你就会知道为啥 epoll 的性能是如此高效了

#### select

我们先来看下 select 函数的定义

```
返回：若有就绪描述符则为其数目，若超时则为 0，若出错则为-1
int select(int maxfd, 
                     fd_set *readset, 
                     fd_set *writeset, 
                     fd_set *exceptset, 
                     const struct timeval *timeout);
```

maxfd 是待测试的描述符基数，为待测试的最大描述符加 1，readset，writeset，exceptset 分别为读描述符集合，写描述符集合，异常描述符集合，这三个分别通知内核，在哪些描述描述符上检测数据可以读，可写，有异常事件发生，timeout 可以设置阻塞时间，如果为 null 代表一直阻塞

这里需要说明一下，为啥 maxfd 为待测试的描述符加 1 呢，主要是因为数组的下标是从 0 开始的，假设进程新建了一个 listenfd，它的 fd 为 3，那么代表它有 4 个 感兴趣的 fd（每个进程有固定的 fd = 0,1,2 这三个描述符），由此可知 maxfd = 3 + 1 = 4

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGuLet1oTqkYOOymQokoxaY3sib3qOfrzOl1iawyYR7y68ry9j8StgtABg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

接下来我们来看看读，写，异常集合是怎么回事，如何设置针对 fd 的感兴趣事件呢，其实事件集合是采用了一种位结构（bitset）的方式，比如现在假设我们对标准输入（fd = 0），listenfd（fd = 3）的读事件感兴趣，那么就可以在 readset 对应的位上置 1

**画外音**：使用 FD_SET 可将相应位置置1，如 FD_SET(listenfd, &readset)

如下

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGBpZLetJID94vEl5NdN9KLiaUCkQSJOnp9Pl4ia27z42UqyuxCZH9ISaw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

即 readset 为 {1, 0,0, 1}，在调用 select 后会将 readset 传给内核，如果内核发现 listenfd 有连接已就绪的事件，则内核也会在将相应位置置 1（其他无就绪事件的 fd 对应的位置为 0）然后会回传给用户线程，此时的 readset 如下，即 {1,0,0,0}

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEG3jwUwYrDEKOEhKy4kicybk8PJB0rB8ialcVTE47pBcX7Rc6WeGIru2Wg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

于是进程就可以根据 readset 相应位置是否是 1（用 FD_ISSET(i, &read_set) 来判断）来判断读事件是否就绪了

需要注意的是由于 accept 的 socket 会越来越多，maxfd 和事件 set 都需要及时调整（比如新 accept 一个已连接的 socket，maxfd 可能会变，另外也需要将其加入到读写描述符集合中以让内核监听其读写事件）

可以看到 select 将感兴趣的事件集合存在一个数组里，然后一次性将数组拷贝给了内核，**这样 n 次系统调用就转化为了一次**，然后用户进程会阻塞在 select 系统调用上，由内核不断循环遍历，如果遍历后发现某些 socket 有事件（accept 或 read/write 准备好了），就会唤醒进程，并且会把数据已就绪的 socket 数量传给用户进程，动图如下

![图片](https://mmbiz.qpic.cn/mmbiz_gif/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGGJKAxtksZwicuyCSopmpUFAGJQsibJyy9jbyMn66d0o82r3SJzWdz1Bw/640?wx_fmt=gif&wxfrom=5&wx_lazy=1)select 图解，图片来自《低并发编程》

select 图解，图片来自《低并发编程》

select 的伪代码如下

```
int listen_fd,conn_fd; //监听套接字和已连接套接字的变量
listen_fd = socket() //创建套接字
bind(listen_fd)   //绑定套接字
listen(listen_fd) //在套接字上进行监听，将套接字转为监听套接字

fd_set master_rset;  //被监听的描述符集合，关注描述符上的读事件

int max_fd = listen_fd

//初始化 master_rset 数组，使用 FD_ZERO 宏设置每个元素为 0 
FD_ZERO(&master_rset);
//使用 FD_SET 宏设置 master_rset 数组中位置为 listen_fd 的文件描述符为 1，表示需要监听该文件描述符
FD_SET(listen_fd,&master_rset);

fd_set working_set;

while(1) {

   // 每次都要将 master_set copy 给 working_set，因为 select 返回后 working_set 会被内核修改
     working_set = master_set
   /**
    * 调用 select 函数，检测 master_rset 数组保存的文件描述符是否已有读事件就绪，
    * 返回就绪的文件描述符个数，我们只关心读事件，所以其它参数都设置为 null 了
    */
   nready = select(max_fd+1, &working_set, NULL, NULL, NULL);

   // 依次检查已连接套接字的文件描述符
   for (i = 0; i < max_fd && nready > 0; i++) {
      // 说明 fd = i 的事件已就绪
      if (FD_ISSET(i, &working_set)) {
          nready -= 1;
          //调用 FD_ISSET 宏，在 working_set 数组中检测 listen_fd 对应的文件描述符是否就绪
         if (FD_ISSET(listen_fd, &working_set)) {
             //如果 listen_fd 已经就绪，表明已有客户端连接；调用 accept 函数建立连接
             conn_fd = accept();
             //设置 master_rset 数组中 conn_fd 对应位置的文件描述符为 1，表示需要监听该文件描述符
             FD_SET(conn_fd, &master_rset);
             if (conn_fd > max_fd) {
                max_fd = conn_fd;
             }
         } else {
            //有数据可读，进行读数据处理
           read(i, xxx)
        }
      }
    }
}
```

看起来 select 很好，但在生产上用处依然不多，主要是因为 select 有以下劣势：

1. 每次调用 select，都需要把 fdset 从用户态拷贝到内核态，在高并发下是个巨大的性能开销（可优化为不拷贝）
2. 调用 select 阻塞后，用户进程虽然没有轮询，但在内核还是通过遍历的方式来检查 fd 的就绪状态（可通过异步 IO 唤醒的方式）
3. select 只返回已就绪 fd 的数量，用户线程还得再遍历所有的 fd 查看哪些 fd 已准备好了事件（可优化为直接返回给用户进程数据已就绪的 fd 列表）

正在由于 1，2 两个缺点，所以 select 限制了 maxfd 的大小为 1024，表示只能监听 1024 个 fd 的事件，这离 C10k 显然还是有距离的

#### poll

poll 的机制其实和 select 一样，唯一比较大的区别其实是把 1024 这个限制给放开了，虽然通过放开限制可以使内核监听上万 socket，但由于以上说的两点劣势，它的性能依然不高，所以生产上也不怎么使用

#### epoll

接下来我们再来介绍下生产上用得最多的 epoll，epoll 其实和 select，poll 这两个系统调用不一样，它本来其实是个内核的数据结构，这个数据结构允许进程监听多个 socket 的 事件，一般我们通过 epoll_create 来创建这个实例

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGroqeLnfCAfnibFRbpQGjAwSicUNmuA0g8fdJIteAdRPJIIp4uSe1oWPQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

然后我们再调用 epoll_ctl 把 感兴趣的 fd 加入到 epoll 实例中的 interest_list，然后再调用 **epoll_wait** 即可将控制权交给内核，这样内核就会检测此 interest_list，如果发现 socket 已就绪就会把已就绪的 fd 加入到一个 ready_list（简称 rdlist） 中，然后再唤醒用户进程，之后用户进程只要遍历此 rdlist 即可

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGk439PxicWJx4yVWluLgEM5siay0icSLuqyv6YTLI94N1Tn1MMI0hTCtCA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

为了方便快速对 fd 进行增删改查，必须设计好 interest list 的数据结构，经综合考虑，内核使用了红黑树，而 rdlist 则采用了链表的形式，这样一旦在红黑树上发现了就绪的 socket ，就会把它放到 rdlist 中

epoll 的伪代码如下

```
int sock_fd,conn_fd; //监听套接字和已连接套接字的变量
sock_fd = socket() //创建套接字
bind(sock_fd)   //绑定套接字
listen(sock_fd) //在套接字上进行监听，将套接字转为监听套接字

epfd = epoll_create(); //创建epoll实例，
//创建epoll_event结构体数组，保存套接字对应文件描述符和监听事件类型    
ep_events = (epoll_event*)malloc(sizeof(epoll_event) * EPOLL_SIZE);

//创建epoll_event变量
struct epoll_event ee
//监听读事件
ee.events = EPOLLIN;
//监听的文件描述符是刚创建的监听套接字
ee.data.fd = sock_fd;

//将监听套接字加入到监听列表中    
epoll_ctl(epfd, EPOLL_CTL_ADD, sock_fd, &ee); 

while (1) {
   //等待返回已经就绪的描述符 
   n = epoll_wait(epfd, ep_events, EPOLL_SIZE, -1); 
   //遍历所有就绪的描述符     
   for (int i = 0; i < n; i++) {
       //如果是监听套接字描述符就绪，表明有一个新客户端连接到来 
       if (ep_events[i].data.fd == sock_fd) { 
          conn_fd = accept(sock_fd); //调用accept()建立连接
          ee.events = EPOLLIN;  
          ee.data.fd = conn_fd;
          //添加对新创建的已连接套接字描述符的监听，监听后续在已连接套接字上的读事件      
          epoll_ctl(epfd, EPOLL_CTL_ADD, conn_fd, &ee); 

       } else { //如果是已连接套接字描述符就绪，则可以读数据
           ...//读取数据并处理
           read(ep_events[i].data.fd, ..)
       }
   }
}
```

epoll 的动图如下

![图片](https://mmbiz.qpic.cn/mmbiz_gif/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGGCN5go7pQicFO7ER5dcTbglaDuL83Gpp5tzxIxfORhhP3iaPbJYVkUBg/640?wx_fmt=gif&wxfrom=5&wx_lazy=1)epoll 图解，图片来自《低并发编程》

epoll 图解，图片来自《低并发编程》

可以看到 epoll 很好地解决了 select 的痛点

1. 「每次调用 select 都把 fd 集合拷贝给内核」**优化为**「只有第一次调用 epoll_ctl 添加感兴趣的 fd 到内核的 epoll 实例中，之后只要调用 epoll_wait 即可，数据集合不再需要拷贝」
2. 「用户进程调用 select 阻塞后，内核会通过遍历的方式来同步检查 fd 的就绪状态」**优化为**「内核使用异步事件通知」
3. 「select 仅返回已就绪 fd 的数量，用户线程还得再遍历一下所有的 fd 来挨个检查哪个 fd 的事件已就绪了」**优化为**「内核直接返回已就绪的 fd 集合」

除了以上针对 select 痛点进行的改进之外，epoll 还引入了一种边缘触发（edge trigger，ET）的模式，这种模式也会让 epoll 在高并发下的表现更加优秀，而 select/poll 则只有水平触发模式（level trigger，LT），首先我们来了解一下什么是水平触发和边缘触发

- **水平触发**：只要读缓冲区可读（或可写缓冲区可写），就会一直触发可读（或可写）信号

  ![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGmWQDLdVmWsIiaQHa3pKgEsHJNLsVhm8SlxYPJDricTmgjGnJ1LfQND9g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- 边缘触发：当套接字的缓冲状态发生变化时才会触发读写信号。对于读缓冲，有新到达的数据被添加到读缓冲时才触发

  ![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGV8fh4IabwUagemcQuTCLcTE1l4AicRLwJCk7rMf68x7VNb0qtA6IuEw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

对于水平触发而言，只要缓冲区里还有数据，内核就会不停地触发读事件，也就意味着如果收到了大量的数据而应用程序每次只会读取一小部分数据时就会不停地从内核态切换到用户态，浪费大量的内核资源，而对于边缘触发而言，只有在套接字的缓冲状态发生变化（即新收到数据或刚好发出数据）时才会触发读写信号，也就意味着内核只通知唤醒用户进程一次，这在高并发下无疑是更佳选择，当然了也正是由于边缘触发模式下内核只会触发一次的原因，read 要尽可能地将数据全部读走（一般是在一个循环里不断地 read ，直到没有数据），否则一旦没有新的数据进来，缓冲区中剩余的数据就无法读取了

既然 epoll 这么好，那么它的性能到底比 select，poll 强多少呢，关于这一点，我们最好做对其进行做下压测，我们来看下 libevent 框架对 select，poll，Epoll，Kqueue（可以认为是 mac 下的 epoll）的压测数据

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGx1diahk7YAQyL0zwpm0uSpuL1IPpIGCgTdqRmV3EB7zHkYFC0RKThyQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)640

640

可以看到，**在 100 活跃连接（所谓活跃连接就是读写比较频繁），每个连接发生 1000 次读写操作的情况下**，随着句柄数量的增加，epoll 和 Kqueue 的响应时间几乎不变，而 select 和 poll 的响应时间则是急遽增加，所以 **epoll 非常适合应对大量网络连接，少量活跃连接的情况**

不过需要注意一下这里的**限制条件**：epoll 在应对大量网络连接时，只有在**活跃连接数较少**的情况下性能才表现优异，如果图中 15000 的网络连接都是活跃连接，那么 epoll 和 select 的表现是差不多的，甚至有可能 epoll 还不如 select，为什么会这样呢？

1. select/poll 的开销主要是因为无论就绪的 fd 有多少，都要遍历一遍全部的 fd 来找到就绪的 fd 再处理，如果活跃连接数很少，那么很多时间都浪费在遍历上了，但如有很多活跃连接，那遍历的开销就可忽略不计

2. 为什么活跃连接多，epoll 表现反而不佳呢，其实主要是因为在唤醒过程中 epoll 实现较为复杂，比如为了保证就绪队列的写入安全，使用了自旋锁，如下

   ```
   static int ep_poll_callback(wait_queue_entry_t *wait, unsigned mode, int sync, void *key)
   {
      int pwake = 0;
      unsigned long flags;
      struct epitem *epi = ep_item_from_wait(wait);
      struct eventpoll *ep = epi->ep;
      int ewake = 0;
   
      /* 获得自旋锁 ep->lock来保护就绪队列
       * 自旋锁ep->lock在 epoll_wait() 调用的 ep_poll() 里被释放
       * /
      spin_lock_irqsave(&ep->lock, flags);
   
      /* If this file is already in the ready list we exit soon */
      /* 在这里将就绪事件添加到 rdllist */
      if (!ep_is_linked(&epi->rdllink)) {
          list_add_tail(&epi->rdllink, &ep->rdllist);
          ep_pm_stay_awake_rcu(epi);
      }
      ...
   }
   ```

   这样的话如果活跃连接多的话，锁的开销就比较大了

#### IO 多路复用+非阻塞

那么当 IO 多路程复用检查到数据就绪后（select()，poll()，epoll_wait() 返回后），该怎么处理呢，有人说直接 accept，read/write 不就完了，话是没错，但之前我们也说了，这些操作其实默认是阻塞的，**我们需要将其改成非阻塞**，为什么呢，数据不是已经就绪了吗，说明 accept，read/write 这些操作可以正常获取数据啊？

其实数据就绪只是说在调用 select()，poll()，epoll_wait() 返回时的数据是就绪的，但当你再去调用 accept，read/write 时可能就会变成未就绪了，举个例子：当某个 socket 接收缓冲区有新数据分节到达，然后 select 报告这个 socket 描述符可读，但随后，协议栈检查到这个新分节有错误，然后丢弃这个分节，这时候调用 read 则无数据可读，这样的话就会产生一个严重的后果：由于线程阻塞在了 read 上，便再也不能调用 select 来监听 socket 事件了，所以 **IO 多路程复用一定要和非阻塞配合使用**，也就是说要把 listenfd 和 connectfd 设置为非阻塞才行

### Reactor 模式

经过以上介绍相信大家对 IO 多路复用的原理有了比较深刻的理解，我们知道 IO 多路程复用是用一个进程来管理多个 socket 的， 那么是否还有优化的空间呢，我们以 select 为例来拆解一下 IO 多路复用的流程

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGg4fcgTmTrT4SMqJsibMILlDMMjeUQjdPnEt0KB96q1cuPbIT3hibfp1g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

主要流程如下：调用 select 来监听连接，读写事件，收到事件后判断是否是监听 socket 上的事件，是的话调用 accept()，否则判断是否是已连接 socket 上的读写事件，是的话调用 read()，write()

#### 单进程/线程 Reactor

目前这样的写法没有问题，不过所有的逻辑都藕合在一起，可扩展性不是很好，我们可以将相近的功能划分到同一个模块（以类的形式）中如下

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGNhZ5PagLlA57bTJEdXoN99cicqU3WxliajWfEFxqyS7zbwW54OY30tHg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

我们将其分成三个模块，Reactor， Acceptor，Handler，主要工作流程如下

1. Reactor 对象首先调用 select 来监听 socket 事件，收到事件后会通过 dispatch 分发
2. 如果是连接建立事件，则由 Acceptor 处理，Acceptor 通过调用 accept 接收连接，并且会创建一个 Handler 来处理后续的读写等事件
3. 如果不是连接建立事件，则 Reactor 会调用连接对应的 Handler 进行响应，handler 会完成 read，业务处理，write 的完整业务流程

以上这些操作其实和之前的 IO 多路复用一样，所有的的都是由一个进程进行操作的，这里多了一个新名词 Reactor，它指的是对事件的响应，如果来了一个事件就把相应的事件 dispatch 给对应的 acceptor 或 handler 对象来处理，由于整个操作都在一个进程里处理，我们把这种模式称为单 Reactor 模型，单 Reactor 要求对事件的响应要快，比如对数据业务的处理要快，像 Redis 就很适合，因为它的数据都是基于内存操作的（当然像 bigKey 这种异常场景除外）

#### 单 Reactor 多线程模型

如果在单进程 Reactor 模型中，业务处理耗时较长，那么线程就会被阻塞，就无法再处理其它事件了，可能会造成严重的性能问题，而且单进程 Reactor 还有一个劣势，那就是无法充分复用多核的优势，于是人们又提出了 单 Reactor 多线程模型，即把业务处理这一块放到一个线程池中处理

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEGYNHNekRsqcyD8OzMTSwdY5cpRe1L0ficYguWGhMmy3UF06eba8INibjA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

通过这种方式主进程的压力得到了释放，也充分复用了多核优势来提升并发度

但依然有如下两个瓶颈点

1. 子线程处理好数据后需要将其传给 handler 进行发送处理，这涉及到共享数据的互斥和保护机制
2. 主进程承担的所有事件的监听和响应，瞬时的高并发可能成为性能瓶颈

#### 多 Reactor 多进程/线程模型

为以解决单 Reactor 多线程模型存在的两个问题，人们又提出了多 Reactor 多进程/线程模型模块，示意图如下

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLXCkKTDfMhibbKdw44f8YNEG0mhWtOohuHMu6wGSQGKHsUWVsFSSKSW5pTxjumESHZprRUm7ibfQWVg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

工作原理如下

1. 主进程主要负责 accept 连接，接收后会将其传给 subReactor，subReactor 将其连接加入连接队列中来监控其事件
2. 一旦子进程中有新的事件被监听到了，则 subReactor 会将其交给 Handler 进入处理

使用这种方式由于数据的 read，业务处理，write 都在一个线程中处理，所以避免了数据的同步加锁操作，父子进程职责很明确，父进程负责 accept，子进程则负责完成后续业务处理

以上介绍的只是标准的 Reactor 模型，但实际上生产上应用的 Reactor 不一定完全遵照这些标准，可能会有一些变化，比如 Nginx 的 Reactor 虽然也是多 Reactor 多进程模型，但它是一种变体：每个子进程都监听了同一个端口，内核接收到连接已建立的事件后会通过负载均衡的方式将其转给其中一个子进程，然后子进程会将其加入到连接队列中监控其事件，监控到事件后也不会转交给其他线程而是自己处理

### 总结

随着互联网的发展，server 面对的连接越来越多，传统的网络 IO 模型由于在 connect，accept，read/write 这三步中会有阻塞操作，显然无法满足我们 C10K 要求，于是人们提出了多进程/线程模型，每接收一个连接分配一个进程/线程来负责后续的交互，但创建进程/线程本身需要创建堆栈，复制页表等资源，而且进程/线程的上下文切换涉及到用户态，内核态的切换，会造成严重的性能瓶颈，那么把阻塞操作改成非阻塞呢，这样做进程/线程确实是不会被阻塞了，但也意味着 CPU 会做大量的无用功，承担不必要的高负载

综合考虑人们提出了 IO 多路复用这种先进的理念，即一个线程管理监听多个 socket 的事件，当然了其实将 socket 设置成非阻塞的，然后让一个线程不断地去轮询也是能达到一个线程监听多个 socket 的目的，但这样做需要对每个 socket 调用一个 read 系统调用，所以 IO 多路复用还有**另一层更重要的意义**：将多个系统调用转成一个系统调用再交给内核去监听事件。

IO 多路复用主要有三个模型，select，poll，epoll，每一个都是对前者的改进:

1. select 是每次调用时都要把 fd 集合拷贝给内核，而且内核是通过不断遍历这种同步的方式来检查 fd 是否有事件就绪，并且一旦检测到有事件后也只是返回有就绪事件的 fd 的个数，用户线程也需要遍历 fd 集合来查看 fd 是否已就绪，select 限制了 fd 的集合只能有 1024 个
2. poll 和 select 的原理差不多，只不过是放开了 1024 个 fd 的限制，fd 的个数可以任意设置，这样也就让支持 C10k 成为了可能，但由于它的实现机制与 select 类似，所以也存在和 select 一样的性能瓶颈
3. 为了彻底解决 select，poll 的性能瓶颈，epoll 出现了，它把需要监听的 fd 传给内核 epoll 实例，epoll 以红黑树的形式来管理这些 fd，这样每次 epoll 只需调用 epoll_wait 即可将控制权转给内核来监听 fd 的事件，避免了无意义的 fd 集合的拷贝，同时由于红黑树的高效，一旦某个 socket 来事件了，可以迅速从红黑树中查找到相应的 socket，然后再唤醒用户进程，此过程是异步的，比起 select 的同步唤醒又是一大进步，此时唤醒用户进程后，内核会把数据已就绪的 fd 放到一个就绪列表里传给用户进程，用户进程只需要遍历此就绪列表即可，比起 select 需要全部遍历也是一大进步，除此之外 epoll 引入了边缘触发让其在高并发下的表现也更加优异，正是由于 epoll 对 select，poll 的这些改进，也让它成为了 IO 多路复用绝对的王者

IO 多路复用是指用一个进程/线程去监听多个 socket 的事件，也即意味着一旦事件就绪了进程需要快速地处理这些事件（不然其他 socket 事件的处理的会阻塞），这种对 Redis 非常合适，因为它是基于内存操作的，处理非常快，但对于其它的开源框架，只有一个进程/线程显然是不太满足业务需要的，比如业务处理，可能是 CPU 密集型的，如果只一个进程/线程的话，可能会阻塞在业务处理上，于是人们基于 IO 多路复用又提出了 Reactor 模型，Reactor 即对事件的反应，然后派发事件给相应的处理器，Reator 模型有多个变种，如单 Reactor，单 Reactor 多线程，多 Reacor 多进程/线程模型，这三种模型各有各的优势，主要是为了充分利用多线程/多核来提升性能或是为了避免瞬时的高并发让主线程崩溃

由此可见，网络 IO 模型经历了传统的网络 IO 模型 ---> IO 多路程复用（select，poll，epoll） --> Reactor 模型这三个阶段，主要是为了满足日益增长的 C10k 甚至 C100K 等超高连接数的要求。

#### 巨人的肩膀

- [你管这破玩意叫 IO 多路复用](https://mp.weixin.qq.com/s?__biz=Mzk0MjE3NDE0Ng==&mid=2247494866&idx=1&sn=0ebeb60dbc1fd7f9473943df7ce5fd95&scene=21#wechat_redirect)
- 极客时间：从 0 开始学架构
- 极客时间：Java性能调优实战





# Socket粘包问题的3种解决方案，最后一种最完美！

[架构师社区](javascript:void(0);) *2021-01-07 11:23*

以下文章来源于Java中文社群 ，作者磊哥

[![img](http://wx.qlogo.cn/mmhead/Q3auHgzwzM5YeKpicFgUMjMibN16U7WXgrTmDNc1fIDbQyeTCPDXpo1g/0)**Java中文社群**.Java实用文章聚集地。](https://mp.weixin.qq.com/s?search_click_id=10789908721810656255-1666678265303-9319854487&__biz=MzU0OTE4MzYzMw==&mid=2247502283&idx=5&sn=21ff778da2386e3b12cfc0ea6eb99b23&chksm=fbb14035ccc6c92322244dc01a4935adfe937e5ec0171195d4e96108e7c1b45d0bfb6ca8aa93&scene=7&key=75926c600950cde188bd5ab301219aef1b7aaa9452b4ac09c0473256d538b6cd2bf604d92ef4c96ffd4872aa0842710ff8362a48f8da19c68c57a5c7c0bd32afc8fb85886837411e57df1b2bcd490271df4aa77cd4d431b3ac2d506f6ed29b4aa10bfc5768cba64b8ab4876a25f2f79470be79cbadbe9ce57acee57fe012c42e&ascene=41&uin=MzEwNTgzNzQ0&devicetype=Windows+10+x64&version=6307062c&lang=zh_CN&exportkey=n_ChQIAhIQZAOTT5wbFrtplyE%2B%2B8xDmxLgAQIE97dBBAEAAAAAAJB2B3aUQ3oAAAAOpnltbLcz9gKNyK89dVj0008d4%2BqSRVAAcwHop0nBqp4RhcBVSl2XaZXALhU%2FvEjG1%2BlVKppWM%2B1%2F9oUsjuXF5x1ymBGy%2BQLE5vrEM10MojXGC6XY97hgzIMRhZm4ZTJD9KBK1A%2B2na0cUq4lY6WIXZhRqYD1z%2BscKvBx3dWapTArGUBzjtbP7Iqlvj2Ze6qhUzd1aL7zY2RsTTh7oeeCD8WV5qYUwuWW2JiCPPFMAEAhaPlZdm3nYlzyXA1RaDN2o6bS8SmGzaoJ&acctmode=0&pass_ticket=%2BI7BUClSxr0%2F4lCjs3tdDBb8QTadh2iCAy8ahBcUNFttP1puQMjWH4t1vo8nfVfi&wx_header=0&fontgear=2#)

作者 | 王磊

来源 | Java中文社群（ID：javacn666）

在  Java 语言中，传统的 Socket 编程分为两种实现方式，这两种实现方式也对应着两种不同的传输层协议：TCP 协议和 UDP 协议，但作为互联网中最常用的传输层协议 TCP，在使用时却会导致粘包和半包问题，于是为了彻底的解决此问题，便诞生了此篇文章。

## 什么是 TCP 协议？

TCP 全称是 Transmission Control Protocol（传输控制协议），它由 IETF 的 RFC 793 定义，是一种面向连接的点对点的传输层通信协议。

TCP 通过使用序列号和确认消息，从发送节点提供有关传输到目标节点的数据包的传递的信息。TCP 确保数据的可靠性，端到端传递，重新排序和重传，直到达到超时条件或接收到数据包的确认为止。



![图片](https://mmbiz.qpic.cn/mmbiz_png/HrWw6ZuXCsjJdLV9FFByyMHJW4cicQlDtDIvXNDJGuzBDh5y011e8pVMmKTUVjic2liarslmLBaMSOPYvGybTY2zA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

TCP 是 Internet 上最常用的协议，它也是实现 HTTP（HTTP 1.0/HTTP 2.0）通讯的基础，当我们在浏览器中请求网页时，计算机会将 TCP 数据包发送到 Web 服务器的地址，要求它将网页返还给我们，Web 服务器通过发送 TCP 数据包流进行响应，然后浏览器将这些数据包缝合在一起以形成网页。

TCP 的全部意义在于它的可靠性，它通过对数据包编号来对其进行排序，而且它会通过让服务器将响应发送回浏览器说“已收到”来进行错误检查，因此在传输过程中不会丢失或破坏任何数据。

目前市场上主流的 HTTP 协议使用的版本是 HTTP/1.1，如下图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/HrWw6ZuXCsjJdLV9FFByyMHJW4cicQlDtpcMp6pZHZB1tW3Z8rx5SafDNGEkXMkzaibfwRmIWkYccqVvbficay3Ag/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 什么是粘包和半包问题？

粘包问题是指当发送两条消息时，比如发送了 ABC 和 DEF，但另一端接收到的却是 ABCD，像这种一次性读取了两条数据的情况就叫做粘包（正常情况应该是一条一条读取的）。![图片](https://mmbiz.qpic.cn/mmbiz_png/HrWw6ZuXCsjJdLV9FFByyMHJW4cicQlDtEvLWQtek949rrZZUsSWtfeSxfy6RHysuibxA2Va8SXIibiaocoIOczia5Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

半包问题是指，当发送的消息是 ABC 时，另一端却接收到的是 AB 和 C 两条信息，像这种情况就叫做半包。![图片](https://mmbiz.qpic.cn/mmbiz_png/HrWw6ZuXCsjJdLV9FFByyMHJW4cicQlDtmjNcD4ibuzHmYePKJ8v1s4NbnmmyX6jHI7GqUBft2EiaNUKWA6wFPokQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 为什么会有粘包和半包问题？

这是**因为 TCP 是面向连接的传输协议，TCP 传输的数据是以流的形式，而流数据是没有明确的开始结尾边界，所以 TCP 也没办法判断哪一段流属于一个消息**。

### 粘包的主要原因：

- 发送方每次写入数据 < 套接字（Socket）缓冲区大小；
- 接收方读取套接字（Socket）缓冲区数据不够及时。

### 半包的主要原因：

- 发送方每次写入数据 > 套接字（Socket）缓冲区大小；
- 发送的数据大于协议的 MTU (Maximum Transmission Unit，最大传输单元)，因此必须拆包。

### 小知识点：什么是缓冲区？

缓冲区又称为缓存，它是内存空间的一部分。也就是说，在内存空间中预留了一定的存储空间，这些存储空间用来缓冲输入或输出的数据，这部分预留的空间就叫做缓冲区。

缓冲区的优势以文件流的写入为例，如果我们不使用缓冲区，那么每次写操作 CPU 都会和低速存储设备也就是磁盘进行交互，那么整个写入文件的速度就会受制于低速的存储设备（磁盘）。但如果使用缓冲区的话，每次写操作会先将数据保存在高速缓冲区内存上，当缓冲区的数据到达某个阈值之后，再将文件一次性写入到磁盘上。因为内存的写入速度远远大于磁盘的写入速度，所以当有了缓冲区之后，文件的写入速度就被大大提升了。

## 粘包和半包问题演示

接下来我们用代码来演示一下粘包和半包问题，为了演示的直观性，我会设置两个角色：

- 服务器端用来接收消息；
- 客户端用来发送一段固定的消息。

然后通过打印服务器端接收到的信息来观察粘包和半包问题。

服务器端代码如下：

```
/**
 * 服务器端（只负责接收消息）
 */
class ServSocket {
    // 字节数组的长度
    private static final int BYTE_LENGTH = 20;  
    public static void main(String[] args) throws IOException {
        // 创建 Socket 服务器
        ServerSocket serverSocket = new ServerSocket(9999);
        // 获取客户端连接
        Socket clientSocket = serverSocket.accept();
        // 得到客户端发送的流对象
        try (InputStream inputStream = clientSocket.getInputStream()) {
            while (true) {
                // 循环获取客户端发送的信息
                byte[] bytes = new byte[BYTE_LENGTH];
                // 读取客户端发送的信息
                int count = inputStream.read(bytes, 0, BYTE_LENGTH);
                if (count > 0) {
                    // 成功接收到有效消息并打印
                    System.out.println("接收到客户端的信息是:" + new String(bytes));
                }
                count = 0;
            }
        }
    }
}
```

客户端代码如下：

```
/**
 * 客户端（只负责发送消息）
 */
static class ClientSocket {
    public static void main(String[] args) throws IOException {
        // 创建 Socket 客户端并尝试连接服务器端
        Socket socket = new Socket("127.0.0.1", 9999);
        // 发送的消息内容
        final String message = "Hi,Java."; 
        // 使用输出流发送消息
        try (OutputStream outputStream = socket.getOutputStream()) {
            // 给服务器端发送 10 次消息
            for (int i = 0; i < 10; i++) {
                // 发送消息
                outputStream.write(message.getBytes());
            }
        }
    }
}
```

以上程序的通讯结果如下图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/HrWw6ZuXCsjJdLV9FFByyMHJW4cicQlDt6LVia2wz9swTiaUjkdD6DZLeILGzC3NnWOOPfiaoJqbIr3tK2XIxS55Dw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)通过上述结果我们可以看出，服务器端发生了粘包和半包的问题，因为客户端发送了 10 次固定的“Hi,Java.”的消息，正常的结果应该是服务器端也接收到了 10 次固定的消息才对，但现实的结果并非如此。

## 粘包和半包的解决方案

粘包和半包的解决方案有以下 3 种：

1. 发送方和接收方规定固定大小的缓冲区，也就是发送和接收都使用固定大小的 byte[] 数组长度，当字符长度不够时使用空字符弥补；
2. 在 TCP 协议的基础上封装一层数据请求协议，既将数据包封装成数据头（存储数据正文大小）+ 数据正文的形式，这样在服务端就可以知道每个数据包的具体长度了，知道了发送数据的具体边界之后，就可以解决半包和粘包的问题了；
3. 以特殊的字符结尾，比如以“\n”结尾，这样我们就知道结束字符，从而避免了半包和粘包问题（**推荐解决方案**）。

那么接下来我们就来演示一下，以上解决方案的具体代码实现。

## 解决方案1：固定缓冲区大小

固定缓冲区大小的实现方案，只需要控制服务器端和客户端发送和接收字节的（数组）长度相同即可。

服务器端实现代码如下：

```
/**
 * 服务器端，改进版本一（只负责接收消息）
 */
static class ServSocketV1 {
    private static final int BYTE_LENGTH = 1024;  // 字节数组长度（收消息用）
    public static void main(String[] args) throws IOException {
        ServerSocket serverSocket = new ServerSocket(9091);
        // 获取到连接
        Socket clientSocket = serverSocket.accept();
        try (InputStream inputStream = clientSocket.getInputStream()) {
            while (true) {
                byte[] bytes = new byte[BYTE_LENGTH];
                // 读取客户端发送的信息
                int count = inputStream.read(bytes, 0, BYTE_LENGTH);
                if (count > 0) {
                    // 接收到消息打印
                    System.out.println("接收到客户端的信息是:" + new String(bytes).trim());
                }
                count = 0;
            }
        }
    }
}
```

客户端实现代码如下：

```
/**
 * 客户端，改进版一（只负责接收消息）
 */
static class ClientSocketV1 {
    private static final int BYTE_LENGTH = 1024;  // 字节长度
    public static void main(String[] args) throws IOException {
        Socket socket = new Socket("127.0.0.1", 9091);
        final String message = "Hi,Java."; // 发送消息
        try (OutputStream outputStream = socket.getOutputStream()) {
            // 将数据组装成定长字节数组
            byte[] bytes = new byte[BYTE_LENGTH];
            int idx = 0;
            for (byte b : message.getBytes()) {
                bytes[idx] = b;
                idx++;
            }
            // 给服务器端发送 10 次消息
            for (int i = 0; i < 10; i++) {
                outputStream.write(bytes, 0, BYTE_LENGTH);
            }
        }
    }
}
```

以上代码的执行结果如下图所示：



### 优缺点分析

从以上代码可以看出，虽然这种方式可以解决粘包和半包的问题，但这种固定缓冲区大小的方式增加了不必要的数据传输，因为这种方式当发送的数据比较小时会使用空字符来弥补，所以这种方式就大大的增加了网络传输的负担，所以它也不是最佳的解决方案。

## 解决方案二：封装请求协议

这种解决方案的实现思路是将请求的数据封装为两部分：数据头+数据正文，在数据头中存储数据正文的大小，当读取的数据小于数据头中的大小时，继续读取数据，直到读取的数据长度等于数据头中的长度时才停止。

因为这种方式可以拿到数据的边界，所以也不会导致粘包和半包的问题，但这种实现方式的编码成本较大也不够优雅，因此不是最佳的实现方案，因此我们这里就略过，直接来看最终的解决方案吧。

## 解决方案三：特殊字符结尾，按行读取

以特殊字符结尾就可以知道流的边界了，因此也可以用来解决粘包和半包的问题，**此实现方案是我们推荐最终解决方案**。

这种解决方案的核心是，使用 Java 中自带的 `BufferedReader` 和 `BufferedWriter`，也就是带缓冲区的输入字符流和输出字符流，通过写入的时候加上 `\n` 来结尾，读取的时候使用 `readLine` 按行来读取数据，这样就知道流的边界了，从而解决了粘包和半包的问题。

服务器端实现代码如下：

```
/**
 * 服务器端，改进版三(只负责收消息)
 */
static class ServSocketV3 {
    public static void main(String[] args) throws IOException {
        // 创建 Socket 服务器端
        ServerSocket serverSocket = new ServerSocket(9092);
        // 获取客户端连接
        Socket clientSocket = serverSocket.accept();
        // 使用线程池处理更多的客户端
        ThreadPoolExecutor threadPool = new ThreadPoolExecutor(100, 150, 100,
                TimeUnit.SECONDS, new LinkedBlockingQueue<>(1000));
        threadPool.submit(() -> {
            // 消息处理
            processMessage(clientSocket);
        });
    }
    /**
     * 消息处理
     * @param clientSocket
     */
    private static void processMessage(Socket clientSocket) {
        // 获取客户端发送的消息流对象
        try (BufferedReader bufferedReader = new BufferedReader(
                new InputStreamReader(clientSocket.getInputStream()))) {
            while (true) {
                // 按行读取客户端发送的消息
                String msg = bufferedReader.readLine();
                if (msg != null) {
                    // 成功接收到客户端的消息并打印
                    System.out.println("接收到客户端的信息:" + msg);
                }
            }
        } catch (IOException ioException) {
            ioException.printStackTrace();
        }
    }
}
```

> PS：上述代码使用了线程池来解决多个客户端同时访问服务器端的问题，从而实现了一对多的服务器响应。

客户端的实现代码如下：

```
/**
 * 客户端，改进版三(只负责发送消息)
 */
static class ClientSocketV3 {
    public static void main(String[] args) throws IOException {
        // 启动 Socket 并尝试连接服务器
        Socket socket = new Socket("127.0.0.1", 9092);
        final String message = "Hi,Java."; // 发送消息
        try (BufferedWriter bufferedWriter = new BufferedWriter(
                new OutputStreamWriter(socket.getOutputStream()))) {
            // 给服务器端发送 10 次消息
            for (int i = 0; i < 10; i++) {
                // 注意:结尾的 \n 不能省略,它表示按行写入
                bufferedWriter.write(message + "\n");
                // 刷新缓冲区(此步骤不能省略)
                bufferedWriter.flush();
            }
        }
    }
}
```

以上代码的执行结果如下图所示：


![图片](https://mmbiz.qpic.cn/mmbiz_png/HrWw6ZuXCsjJdLV9FFByyMHJW4cicQlDtZ7wofib0odtRAlcgZmnyfThJchq2wG0ArM6xiajicUQDUg40CMMhicPd0A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 总结

本文我们讲了 TCP 粘包和半包问题，粘包是指读取到了两条信息，正常情况下消息应该是一条一条读取的，而半包问题是指读取了一半信息。导致粘包和半包的原因是 TCP 的传输是以流的形式进行的，而流数据是没有明确的开始和结尾标识的，因此就导致了此问题。

本文我们提供了 3 种粘包和半包的解决方案，其中最推荐的是使用 `BufferedReader` 和 `BufferedWriter` 按行来读、写和区分消息，也就是本文的第三种解决方案。

#### 参考 & 鸣谢

https://zhuanlan.zhihu.com/p/126279630

https://www.jianshu.com/p/6a4ec6095f2c